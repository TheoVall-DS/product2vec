{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from product2vec import BasketGenerator, Product2Vec, EpochLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original paper: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3519358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product2Vec model is capable of finding complements (complementarity goods) and substitutes (interchangeable goods). Complementarity products are those which bring more utility when used together (i.e. cereal and milk). Interchangeable products are those which have identical properties and can possess the same (almost) utility for a buyer (coffee and tea to some extent).\n",
    "\n",
    "Product2Vec uses Word2Vec under the hood to build embeddings for each product. But embeddings themselves don't help distinguish between complements and substitutes. Therefore it calculates special scores (exchangeability and complementarity scores) to make a desicion. Higher score result in greater probability for a product to be a complement/substitute.\n",
    "\n",
    "The only source of data model needs is shopping baskets with purchased goods. Their order within basket doesn't matter and, thus, repeated labels don't bring any additional value. All baskets should have at least two unique products.\n",
    "\n",
    "Put it simply, Product2Vec considers two products as complements if they frequently occur in the same basket, and it considers two products as substitutes if they are frequently bought with similar products within the same basket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate synthetic baskets with product labels from '0' to '1000' randomly put in 100000 baskets. To be precise, basket generation is based on copurchase matrix (generated randomly) which assigns probabilities of two products occuring in the same bakset. Basket size can vary according to specified boundaries. Refer to the source code for more comments on implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1420 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 31500 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 76300 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100000 out of 100000 | elapsed:   15.8s finished\n"
     ]
    }
   ],
   "source": [
    "generator = BasketGenerator(\n",
    "    n_jobs=-1,  # number of workers\n",
    "    verbose=1,  # verbosity level\n",
    "    seed=1,  # random seed\n",
    "    extreme=10,  # how extremen copurchase probabilities can be\n",
    ")\n",
    "data = generator(\n",
    "    n_baskets=100000,  #  number of baskets\n",
    "    n_products=1000,  # number of unique products\n",
    "    min_size=2,  # minimum number of unique products in the same basket, should be > 2\n",
    "    max_size=10,  # maximum basket of unique products in the same basket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting model and logging progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EpochLogger prints current epoch and linear estimate of time left. Product2Vec model accepts all gensim Word2Vec parameters except for:\n",
    "- sentences (passed to `fit` method)\n",
    "- window (take the whole basket, set to 1000)\n",
    "- sg (set to 1, allow skip-gram approach)\n",
    "- hs (set to 0, allow negative sampling)\n",
    "- shrink_windows (set to False, fixed window size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1. Estimated time left - To be estimated\n",
      "Epoch #2. Estimated time left - 00:10\n",
      "Epoch #3. Estimated time left - 00:09\n",
      "Epoch #4. Estimated time left - 00:08\n",
      "Epoch #5. Estimated time left - 00:07\n",
      "Epoch #6. Estimated time left - 00:06\n",
      "Epoch #7. Estimated time left - 00:04\n",
      "Epoch #8. Estimated time left - 00:03\n",
      "Epoch #9. Estimated time left - 00:02\n",
      "Epoch #10. Estimated time left - 00:01\n"
     ]
    }
   ],
   "source": [
    "logger = EpochLogger(n_latest=5)  # how many latest epochs to use to estimate time left\n",
    "\n",
    "#  refer to the original paper for optimal learning parameters\n",
    "prod2vec = Product2Vec(\n",
    "    vector_size=10, epochs=10, callbacks=[logger], seed=1, workers=4\n",
    ")\n",
    "_ = prod2vec.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting you can access gensim model via `.model_` attribute of Product2Vec instance. It has all methods and attributes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21477434,  0.03511613, -0.439563  , -0.37581408,  0.1593026 ,\n",
       "        0.6893432 ,  0.06630325, -0.30754682, -0.6433185 , -0.743252  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod2vec.model_.wv[\"0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complementarity and exchangeability scores are not computed untill you call `show_complements` or `show_substitutes` methods. It might take some time in case number of unique products found in baskets during fit is huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('786', -0.6277325),\n",
       " ('832', -0.6468932),\n",
       " ('760', -0.6767897),\n",
       " ('991', -0.68854976),\n",
       " ('83', -0.6892245),\n",
       " ('815', -0.7061493),\n",
       " ('978', -0.725211),\n",
       " ('673', -0.7273524),\n",
       " ('825', -0.73150086),\n",
       " ('661', -0.7356517)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod2vec.show_substitutes(\n",
    "    product=\"0\",  # focal product label\n",
    "    topn=10,  # top N subsitutes\n",
    "    penalize=True,  # penalization flag, setting to True is highly recommended\n",
    "    # guess=1,  # tweak between -10 and 10 if you get OptimizationWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('867', 0.26756227),\n",
       " ('673', 0.26403713),\n",
       " ('835', 0.2512554),\n",
       " ('165', 0.24923748),\n",
       " ('871', 0.24331644),\n",
       " ('978', 0.23695599),\n",
       " ('800', 0.23505902),\n",
       " ('716', 0.23462863),\n",
       " ('825', 0.23426346),\n",
       " ('403', 0.23408276)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod2vec.show_complements(\n",
    "    product=\"0\",  # focal product label\n",
    "    topn=10,  # top N complements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save and load model with pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fitted_model.pkl', 'wb') as file:\n",
    "    pickle.dump(prod2vec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fitted_model.pkl', 'rb') as file:\n",
    "    pickled_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('867', 0.26756227),\n",
       " ('673', 0.26403713),\n",
       " ('835', 0.2512554),\n",
       " ('165', 0.24923748),\n",
       " ('871', 0.24331644)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_model.show_complements('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
